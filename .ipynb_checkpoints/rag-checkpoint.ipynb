{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (6.29.4)\n",
      "Requirement already satisfied: python-dotenv in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: langchain in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (0.2.14)\n",
      "Requirement already satisfied: langchain_community in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.2.12)\n",
      "Requirement already satisfied: langchain_core in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.2.34)\n",
      "Requirement already satisfied: pypdf in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (4.3.1)\n",
      "Requirement already satisfied: sentence_transformers in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: faiss-cpu in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (1.8.0.post1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/app-root/lib/python3.9/site-packages (from ipykernel->-r requirements.txt (line 1)) (8.18.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/app-root/lib/python3.9/site-packages (from ipykernel->-r requirements.txt (line 1)) (7.4.9)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/app-root/lib/python3.9/site-packages (from ipykernel->-r requirements.txt (line 1)) (1.8.2)\n",
      "Requirement already satisfied: nest-asyncio in /opt/app-root/lib/python3.9/site-packages (from ipykernel->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/app-root/lib/python3.9/site-packages (from ipykernel->-r requirements.txt (line 1)) (5.14.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/app-root/lib/python3.9/site-packages (from ipykernel->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/app-root/lib/python3.9/site-packages (from ipykernel->-r requirements.txt (line 1)) (6.4.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/app-root/lib/python3.9/site-packages (from ipykernel->-r requirements.txt (line 1)) (5.7.2)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib/python3.9/site-packages (from ipykernel->-r requirements.txt (line 1)) (24.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/app-root/lib/python3.9/site-packages (from ipykernel->-r requirements.txt (line 1)) (26.0.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/app-root/lib/python3.9/site-packages (from ipykernel->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib/python3.9/site-packages (from ipykernel->-r requirements.txt (line 1)) (5.9.8)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/app-root/lib/python3.9/site-packages (from langchain->-r requirements.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/app-root/lib/python3.9/site-packages (from langchain->-r requirements.txt (line 3)) (3.9.5)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/app-root/lib/python3.9/site-packages (from langchain->-r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/app-root/lib/python3.9/site-packages (from langchain->-r requirements.txt (line 3)) (2.0.32)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/app-root/lib/python3.9/site-packages (from langchain->-r requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/app-root/lib/python3.9/site-packages (from langchain->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/app-root/lib/python3.9/site-packages (from langchain->-r requirements.txt (line 3)) (8.4.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/app-root/lib/python3.9/site-packages (from langchain->-r requirements.txt (line 3)) (6.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/app-root/lib/python3.9/site-packages (from langchain->-r requirements.txt (line 3)) (0.1.101)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/app-root/lib/python3.9/site-packages (from langchain->-r requirements.txt (line 3)) (1.10.17)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/app-root/lib/python3.9/site-packages (from langchain_community->-r requirements.txt (line 4)) (0.6.7)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/app-root/lib/python3.9/site-packages (from langchain_core->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/app-root/lib/python3.9/site-packages (from langchain_core->-r requirements.txt (line 5)) (1.33)\n",
      "Requirement already satisfied: scipy in /opt/app-root/lib/python3.9/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (1.12.0)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib/python3.9/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/app-root/lib/python3.9/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (2.4.0)\n",
      "Requirement already satisfied: Pillow in /opt/app-root/lib/python3.9/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (10.3.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/app-root/lib/python3.9/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/app-root/lib/python3.9/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (4.44.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/app-root/lib/python3.9/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (0.24.6)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (6.0.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (23.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (1.9.4)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/app-root/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/app-root/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 4)) (3.22.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence_transformers->-r requirements.txt (line 7)) (2024.6.1)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence_transformers->-r requirements.txt (line 7)) (3.15.4)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/app-root/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (3.0.47)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/app-root/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/app-root/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (2.18.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/app-root/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: decorator in /opt/app-root/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/app-root/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.19.1)\n",
      "Requirement already satisfied: stack-data in /opt/app-root/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/app-root/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain_core->-r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: entrypoints in /opt/app-root/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 1)) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/app-root/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/app-root/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 3)) (3.10.7)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 3)) (0.27.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 3)) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 3)) (2024.6.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 3)) (1.26.19)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/app-root/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (12.1.3.1)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (3.2.1)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (1.13.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/app-root/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (12.6.20)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/app-root/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers->-r requirements.txt (line 7)) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/app-root/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers->-r requirements.txt (line 7)) (0.4.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers->-r requirements.txt (line 7)) (2024.7.24)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/app-root/lib/python3.9/site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 7)) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/app-root/lib/python3.9/site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 3)) (1.0.5)\n",
      "Requirement already satisfied: anyio in /opt/app-root/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 3)) (4.4.0)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/app-root/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 3)) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/app-root/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/app-root/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/app-root/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (2.1.5)\n",
      "Requirement already satisfied: pure-eval in /opt/app-root/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/app-root/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/app-root/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (2.4.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib/python3.9/site-packages (from sympy->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 7)) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing the libraries:\n",
    "#changes in redhat:\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'HR-DigivateLabs-Leave-Policy.pdf', 'page': 0}, page_content='HR-DigivateL abs-Leave -Policy \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nCONTROL  INFORMATION  Leave Policy  \\nHR De partment – Digivate Labs  \\n \\n# Attribute  Value  \\n1 Document  Title Digivate Labs  Leave  Policy  \\n \\n \\nRELEASE  HISTORY  \\n \\n# Date Prepared By  Reviewed By  Approved By  Reason  \\n0.1 1-Apr-22 HR Management  MD & CEO  Released')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the pdf from the folder:\n",
    "loader = PyPDFLoader(\"HR-DigivateLabs-Leave-Policy.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "#splitting into chunks:\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000,chunk_overlap=200)\n",
    "final_document = text_splitter.split_documents(documents)\n",
    "final_document[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initializing embedding technique:\n",
    "hugging_face_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    model_kwargs={'device':'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings':True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creating the vector store:\n",
    "vector_store = FAISS.from_documents(final_document[:],hugging_face_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR-Digivate Labs -Leave-Policy \n",
      "  \n",
      " \n",
      "The above policy shall be applicable to all full time/contract Employees.  \n",
      " \n",
      "Short duration leaves should only be approved by HR after consideration or BU Head and can be done only \n",
      "once or twice in a month.  \n",
      " \n",
      "Carry Forward  \n",
      " \n",
      "You can carry forward a maximum of 7 leaves to a new calendar year. Thus, your leave balance cannot \n",
      "exceed 22 days at any given time. For instance, if you have accumula ted 7 days of leave by the end of a year \n",
      "and have added 13 days by 1st December, your leave balance will be 20. However, if you utilize 10 days \n",
      "during December, your leave balance as on 1st January will still be 7 only.  \n",
      " \n",
      "Encashment  \n",
      " \n",
      "NO ENCASHMENT OF LEAVE. Un -availed leave may be adjusted at the time of separation, at the sole \n",
      "discretion  of the management.  \n",
      " \n",
      "Casual  & Sick Leave  \n",
      " \n",
      "NO SEPARATE CASUAL or SICK LEAVE, ALL LEAVES COMBINED INTO ONE COMMON POOL AS \n",
      "ACCRUED LEAVE . Sick leave exce eding 3 days requires submission of a medical certificate to the line \n",
      "manager with a copy to HR Deptt, to be filed in the employee‟s file.  \n",
      " \n",
      "Maternity Leave  \n",
      " \n",
      "Definitions  \n",
      "o “Maternity Leave” is approved paid leave extended to all women employees who are working in the \n",
      "organization for certain period before and after child birth along with certain benefits.  \n",
      "o A „commissioning mother‟ who as biological mother wishes to have a child and prefers to get embryo \n",
      "implanted in any other woman.  \n",
      "o An „adopting mother‟ w ho legally adopts a child below the age of three months.  \n",
      "o Medical Termination of pregnancy‟‟ means the termination of pregnancy permissible under the \n",
      "provisions of Medical Termination of Pregnancy Act, 1971.  \n",
      "o „‟Miscarriage‟‟ means expulsion of the contents o f a pregnant uterus at any period prior to or during \n",
      "the twenty -sixth week of pregnancy but does not include any miscarriage, the causing of which is \n",
      "punishable under the Indian Penal Code.  \n",
      "o Tubectomy is a surgical procedure for sterilization in which a wom an‟s fallopian tubes are clamped \n",
      "and blocked or severed and sealed to prevent pregnancy.  \n",
      "Eligibility & Duration  \n",
      " \n",
      "All women employees who have worked for a minimum of 80 days of service with the company in the period \n",
      "of twelve months immediately preceding t he date of her expected delivery or child is handed over to the \n",
      "commissioning / adopting mother, or date of miscarriage / medical termination are eligible for paid maternity \n",
      "leave. For employees with less than 80 days service, maternity leave will be treat ed as unpaid leave.  \n",
      " \n",
      "You can also avail of your accumulated leave at the beginning or at the end of your maternity leave. \n",
      "However, no leave will accrue during the entire duration of the maternity leave. Paid holidays and weekly \n",
      "holidays intervening the per iod of ML shall be counted as part of the applicable leaves .\n"
     ]
    }
   ],
   "source": [
    "#Query using similar search:\n",
    "query = \"How many leaves can we carry forward?\"\n",
    "relevant_documents = vector_store.search(query,search_type='similarity')\n",
    "print(relevant_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7ff875d91490>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a retriever object:\n",
    "retriever = vector_store.as_retriever(search_type='similarity',\n",
    "                                      search_kwargs={\"k\":3})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loading the huggingface api key:\n",
    "HUGGINGFACEHUB_API_TOKEN = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loading a hugging face model:\n",
    "llm = HuggingFaceHub(\n",
    "        repo_id=\"mistralai/Mistral-7B-v0.1\",\n",
    "        model_kwargs={\"temperature\":3,\n",
    "                      \"max_length\":1000}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#creating a prompt template:\n",
    "template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved \n",
    "context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "Please provide a detailed to-the-point summary of the following answer:\n",
    "Question: {question} ,\n",
    "Context: {context},\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template,\n",
    "                        input_variables=[\"context\",\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creating a retireval QA:\n",
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\":prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR-Digivate Labs -Leave-Policy \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      "All eligible women employees are entitled to maternity leave, as shown in the table below. The maternity \n",
      "leave is inclusive of weekly offs and public & national holidays.  \n",
      " \n",
      "Types of Maternity \n",
      "Leaves  Leave Entitlement \n",
      "(In Weeks)  Documents required to be \n",
      "submitted to HR Deptt to \n",
      "avail the leave  Leave \n",
      "Commencement  \n",
      "Maternity leave in case \n",
      "of women employee up \n",
      "to two surviving children  26 1. Confirmation of pregnancy \n",
      "along with t he date of delivery.  \n",
      "2. Medical certificate from \n",
      "certified medical practitioner.  Not earlier than 8 \n",
      "weeks prior to the \n",
      "date of delivery.  \n",
      "Maternity leave in case \n",
      "of women employee with \n",
      "two or more children  12 1. Confirmation of pregnancy \n",
      "along with the date of delivery.  \n",
      "2. Medical certificate from \n",
      "certified medical practitioner.  Not earlier than 6 \n",
      "weeks prior to the \n",
      "date of delivery.  \n",
      "Commissioning Mother  12 1. Medical Documents  \n",
      "2. Birth certificate of the ch ild From the date the \n",
      "child is handed over \n",
      "to the commissioning \n",
      "mother after birth.  \n",
      "Leave for \n",
      "miscarriage/medical \n",
      "termination  4 Medical certificate from certified \n",
      "medical practitioner.  Day of the \n",
      "miscarriage/ medical \n",
      "termination  \n",
      "Tubectomy operation  2 Medical certificate from certified \n",
      "medical practitioner.  From the day of the \n",
      "operation.  \n",
      " \n",
      " \n",
      "Conditions  \n",
      " \n",
      "The documents requested are indicative list and more documents can be requested by the organization.  \n",
      " \n",
      "Process  \n",
      " \n",
      "o To avail maternity, the employee must notify the respective line manager of her intent to take \n",
      "maternity leave preferably no later than 15 weeks prior to the date of delivery and apply the leaves in \n",
      "Payasia.A scanned copy of the maternity certificate confi rming the date of delivery and relevant \n",
      "medical documents must be submitted to HR Deptt.  \n",
      "o HR Deptt will respond to an employee‟s notification of leave plans within 28 days of being notified \n",
      "with the details of the expected return to work if the employee tak es her full entitlement.  \n",
      "o In the event that childbirth occurs before the employee is due to commence maternity leave, such \n",
      "maternity leave will automatically start from the date of childbirth.  \n",
      "o The employee is expected to provide a declaration in writing sta ting that the employee will not work in \n",
      "any other establishment during the period for which maternity benefits are being received. Violation of \n",
      "this policy/ clause will be viewed as serious breach of company policy which may result in severe \n",
      "disciplinary a ction including termination of employment.\n"
     ]
    }
   ],
   "source": [
    "#testing the model with a query:\n",
    "query = \"What is the process to avail a maternity leave?\"\n",
    "response = retrievalQA.invoke({\"query\":query})\n",
    "\n",
    "# Fetching only the context from the response:\n",
    "context = response['source_documents'][0].page_content\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('PDF_ChatBot_RatHat/models',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /opt/app-root/src/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Replace 'your_hugging_face_token' with your actual token\n",
    "login(token=HUGGINGFACEHUB_API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2658ddf344b4f9fbdfc697cb2b9b85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4a3ed9243041e6a6a3e141e17a292f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babf66f44e114648a6a379d671298b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fe3e077f044ecb88034cacc60cdb79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d5aa071cd24f628f863cc8ad57a2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b26dfc4d1f4355869e38b703891852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfc4ad5c3b04d3b92030dd02d859bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/huggingface_hub/file_download.py:991: UserWarning: Not enough free disk space to download the file. The expected file size is: 9942.98 MB. The target location /opt/app-root/src/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.1/blobs only has 4874.39 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaffebdabfd04d509492eef9dd7f260c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the tokenizer and model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistralai/Mistral-7B-v0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Set the output path\u001b[39;00m\n\u001b[1;32m     13\u001b[0m output_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDF_ChatBot_RatHat/models/onnx_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/transformers/modeling_utils.py:3715\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3712\u001b[0m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   3713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[1;32m   3714\u001b[0m     \u001b[38;5;66;03m# resolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 3715\u001b[0m     resolved_archive_file, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3724\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3726\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3727\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3728\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3731\u001b[0m     is_safetensors_available()\n\u001b[1;32m   3732\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m   3733\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3734\u001b[0m ):\n\u001b[1;32m   3735\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/transformers/utils/hub.py:1079\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading shards\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1078\u001b[0m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[0;32m-> 1079\u001b[0m         cached_filename \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshard_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/transformers/utils/hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/huggingface_hub/file_download.py:1240\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m   1221\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/huggingface_hub/file_download.py:1389\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1387\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1399\u001b[0m     _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/huggingface_hub/file_download.py:1915\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1912\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1913\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1915\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1924\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1925\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/huggingface_hub/file_download.py:552\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n\u001b[0;32m--> 552\u001b[0m     \u001b[43mtemp_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m     new_resume_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;66;03m# Some data has been downloaded from the server so we reset the number of retries.\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "#saving the model:\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.onnx import export\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "\n",
    "# Set the output path\n",
    "output_path = Path(\"PDF_ChatBot_RatHat/models/onnx_model\")\n",
    "\n",
    "# Export the model to ONNX format\n",
    "export(tokenizer, model, output=output_path, opset=13, use_external_format=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the FAISS index\n",
    "faiss.write_index(vector_store.index, \"faiss_index.index\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
